services:
  control-plane:
    build:
      context: ./control-plane
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - PORT=8080
      - GATEWAY_INTERNAL_URL=http://webrtc-gateway:9091
    depends_on:
      - webrtc-gateway
    restart: unless-stopped

  webrtc-gateway:
    build:
      context: .
      dockerfile: webrtc-gateway/Dockerfile
    ports:
      - "9090:9090"
      - "9091:9091"
      - "9092:9092"
    environment:
      - LISTEN_ADDR=:9090
      - INTERNAL_API_ADDR=:9091
      - METRICS_ADDR=:9092
      - ASR_ADDR=asr:50051
      - TTS_ADDR=tts:50052
      - MAX_SESSIONS=100
      - MAX_INFERENCE_CONCURRENCY=4
      - ACTION_TIMEOUT_SEC=60
      - MAX_LOOKBACK_SEC=30
    depends_on:
      - asr
      - tts
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "2"

  asr:
    build:
      context: .
      dockerfile: inference/asr/Dockerfile
    ports:
      - "50051:50051"
    environment:
      - GRPC_PORT=50051
      - WHISPER_MODEL_SIZE=base
      - WHISPER_DEVICE=cpu
      - WHISPER_COMPUTE_TYPE=int8
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2"
    # For GPU support, uncomment:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  tts:
    build:
      context: .
      dockerfile: inference/tts/Dockerfile
    ports:
      - "50052:50052"
    environment:
      - GRPC_PORT=50052
      - TTS_MODEL_PATH=/app/models/en_US-lessac-medium.onnx
      - TTS_DEVICE=cpu
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "2"

  web-client:
    image: nginx:alpine
    ports:
      - "3000:80"
    volumes:
      - ./clients/web:/usr/share/nginx/html:ro
    depends_on:
      - control-plane
    restart: unless-stopped

networks:
  default:
    name: whats-network
